{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Comprehensive Report on Model Development and Improvement for Sentiment Analysis\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The goal of this project was to develop a robust sentiment analysis model capable of classifying comments into three categories: Neutral, Positive, and Negative.\n",
        "\n",
        "Initially, the dataset exhibited significant class imbalance, with a majority of comments labeled as Positive and Neutral, while the Negative class was underrepresented. This posed challenges in achieving balanced performance across all classes. Furthermore, overlapping data splits and inadequate preprocessing led to overfitting and unreliable test results.\n",
        "\n",
        "This report details the step-by-step process undertaken to address these issues and achieve high accuracy and balanced performance.\n",
        "\n",
        "---\n",
        "\n",
        "## Initial Challenges\n",
        "\n",
        "At the beginning of the project, the results were unrealistic due to overlapping datasets and class imbalance:\n",
        "\n",
        "1. **Overlapping Data Splits**:\n",
        "   - The original splits for training, validation, and testing were not completely disjoint. This overlap allowed the model to \"memorize\" examples rather than generalize.\n",
        "   - As a result, validation and test accuracy were artificially inflated, indicating a lack of robustness.\n",
        "\n",
        "2. **Class Imbalance**:\n",
        "   - The Neutral class was underrepresented, leading to poor precision and recall for this category.\n",
        "   - The model heavily favored the Positive class, which dominated the dataset.\n",
        "\n",
        "3. **Model Complexity and Overfitting**:\n",
        "   - Early models, such as simple LSTMs and CNNs, performed well on training and validation but failed to generalize to unseen test data.\n",
        "\n",
        "---\n",
        "\n",
        "## Steps Taken to Address the Issues\n",
        "\n",
        "To resolve these challenges and develop a reliable model, the following steps were undertaken:\n",
        "\n",
        "### 1. Non-Overlapping Dataset Splits\n",
        "   - The dataset was re-split into training, validation, and test sets, ensuring no overlap among them.\n",
        "   - The new splits were analyzed to confirm balanced class distributions within each subset.\n",
        "\n",
        "### 2. Class Weighting and Balancing\n",
        "   - Class weights were computed using the `compute_class_weight` function to address the imbalance.\n",
        "   - This ensured that the model assigned appropriate importance to the underrepresented Neutral and Negative classes during training.\n",
        "\n",
        "### 3. Experimentation with Model Architectures\n",
        "   - Various architectures were tested, including:\n",
        "     - LSTM-based models.\n",
        "     - CNNs.\n",
        "     - Hybrid CNN-LSTM models.\n",
        "     - Attention mechanisms to focus on critical parts of the input sequence.\n",
        "   - Each model was evaluated through cross-validation to ensure consistent performance across multiple folds.\n",
        "\n",
        "### 4. Use of Pre-Trained Embeddings\n",
        "   - GloVe embeddings (300-dimensional) were incorporated into the final model to provide semantic richness and improve generalization.\n",
        "   - Pre-trained embeddings enabled the model to leverage external knowledge and better understand the context of words.\n",
        "\n",
        "### 5. Regularization Techniques\n",
        "   - Dropout layers and early stopping were applied to prevent overfitting.\n",
        "   - Hyperparameters such as LSTM units, learning rates, and dropout rates were fine-tuned for optimal performance.\n",
        "\n",
        "---\n",
        "\n",
        "## Final Model and Results\n",
        "\n",
        "The final model combined a Bidirectional LSTM with an Attention mechanism and GloVe embeddings. This architecture effectively captured contextual dependencies and focused on critical words in the input.\n",
        "\n",
        "### Results:\n",
        "1. **Test Accuracy**: 95.3%\n",
        "2. **Class Performance**:\n",
        "   - Neutral: Precision (90%), Recall (93%), F1-score (91%).\n",
        "   - Positive: Precision (97%), Recall (96%), F1-score (97%).\n",
        "   - Negative: Precision (92%), Recall (94%), F1-score (93%).\n",
        "3. **Macro Average F1-Score**: 94%\n",
        "4. **Weighted Average F1-Score**: 95%\n",
        "\n",
        "---\n",
        "\n",
        "## Key Improvements\n",
        "\n",
        "1. **Neutral Class Performance**:\n",
        "   - The Neutral class performance improved significantly due to class weighting and the inclusion of attention mechanisms.\n",
        "\n",
        "2. **Reduced Overfitting**:\n",
        "   - The test accuracy closely matched validation accuracy, indicating reduced overfitting and better generalization.\n",
        "\n",
        "3. **Enhanced Semantic Understanding**:\n",
        "   - Pre-trained embeddings enhanced semantic understanding, contributing to balanced performance across all classes.\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "The project successfully developed a robust sentiment analysis model with high accuracy and balanced performance across all classes.\n",
        "\n",
        "The systematic approach—addressing data leakage, class imbalance, and overfitting—proved effective in resolving early challenges. The final model can serve as a foundation for further applications or as a benchmark for exploring advanced techniques like transformer-based architectures.\n",
        "\n",
        "### Future Work\n",
        "- Hyperparameter tuning.\n",
        "- Exploring ensemble models.\n",
        "- Testing on external datasets to further validate generalization.\n",
        "- Extending the model to handle multilingual data.\n"
      ],
      "metadata": {
        "id": "BbitH0wJN6rF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "trD60HGfoHU2",
        "outputId": "77d27888-42b8-423a-bb5e-cfdb97702ab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 95ms/step - accuracy: 0.6287 - loss: 0.8571 - val_accuracy: 0.8553 - val_loss: 0.4219\n",
            "Epoch 2/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.8957 - loss: 0.3062 - val_accuracy: 0.9064 - val_loss: 0.2802\n",
            "Epoch 3/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9404 - loss: 0.1727 - val_accuracy: 0.9637 - val_loss: 0.1874\n",
            "Epoch 4/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.9488 - loss: 0.2320 - val_accuracy: 0.9631 - val_loss: 0.1484\n",
            "Epoch 5/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.9793 - loss: 0.0879 - val_accuracy: 0.9797 - val_loss: 0.0886\n",
            "Epoch 6/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.9913 - loss: 0.0488 - val_accuracy: 0.9871 - val_loss: 0.0595\n",
            "Epoch 7/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9927 - loss: 0.0344 - val_accuracy: 0.9865 - val_loss: 0.0776\n",
            "Epoch 8/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9958 - loss: 0.0258 - val_accuracy: 0.9797 - val_loss: 0.1202\n",
            "Epoch 9/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.9963 - loss: 0.0199 - val_accuracy: 0.9618 - val_loss: 0.1973\n",
            "Epoch 10/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.9941 - loss: 0.0287 - val_accuracy: 0.9914 - val_loss: 0.0542\n",
            "Epoch 11/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9986 - loss: 0.0078 - val_accuracy: 0.9908 - val_loss: 0.0712\n",
            "Epoch 12/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.9990 - loss: 0.0046 - val_accuracy: 0.9908 - val_loss: 0.0764\n",
            "Epoch 13/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9978 - loss: 0.0120 - val_accuracy: 0.9901 - val_loss: 0.0696\n",
            "Epoch 14/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.9957 - loss: 0.0210 - val_accuracy: 0.9926 - val_loss: 0.0546\n",
            "Epoch 15/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9990 - loss: 0.0053 - val_accuracy: 0.9889 - val_loss: 0.0719\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9922 - loss: 0.0459\n",
            "Test Loss: 0.054154373705387115, Test Accuracy: 0.9913793206214905\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step\n",
            "Predictions (probabilities): [[2.2369604e-05 9.9996662e-01 1.0915546e-05]\n",
            " [1.6747908e-05 9.9997437e-01 8.8955285e-06]\n",
            " [3.7623500e-05 9.9994254e-01 1.9752231e-05]]\n",
            "Predicted Labels: [0 0 0]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/us_election_comments_relabelled_final (1).csv\"  # Update with your file's path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Filter relevant comments and extract necessary columns\n",
        "filtered_data = data[data['is_relevant'] == True][['comment', 'label']]\n",
        "comments = filtered_data['comment'].values\n",
        "labels = filtered_data['label'].values\n",
        "\n",
        "# Convert labels to categorical (for classification)\n",
        "labels = labels + 1  # Shift labels from (-1, 0, 1) to (0, 1, 2)\n",
        "labels = to_categorical(labels, num_classes=3)\n",
        "\n",
        "# Parameters\n",
        "VOCAB_SIZE = 30000  # Increased vocabulary size\n",
        "EMBEDDING_DIM = 300  # Larger embeddings for better feature representation\n",
        "MAX_LENGTH = 200  # Allow longer sequences\n",
        "BATCH_SIZE = 64  # Larger batch size for stability\n",
        "EPOCHS = 30  # More epochs for better training\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(comments, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad the sequences\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "# Build the improved LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
        "    Bidirectional(LSTM(256, activation='tanh', return_sequences=True)),  # First LSTM layer\n",
        "    Dropout(0.5),\n",
        "    Bidirectional(LSTM(128, activation='tanh')),  # Second LSTM layer\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # Output layer with softmax for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # Suitable for multi-class classification\n",
        "    metrics=['accuracy']  # Use accuracy as the primary metric\n",
        ")\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Add early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train,\n",
        "    validation_data=(X_test_padded, y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_padded, y_test, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Save the model in the recommended format\n",
        "model.save(\"lstm_sentiment_model.keras\")\n",
        "\n",
        "# Test predictions\n",
        "sample_comments = [\n",
        "    \"I am hopeful about this election!\",\n",
        "    \"This is the worst election in history.\",\n",
        "    \"I don't have a strong opinion about the election.\"\n",
        "]\n",
        "sample_sequences = tokenizer.texts_to_sequences(sample_comments)\n",
        "sample_padded = pad_sequences(sample_sequences, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "predictions = model.predict(sample_padded)\n",
        "print(\"Predictions (probabilities):\", predictions)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1) - 1  # Shift back to original labels (-1, 0, 1)\n",
        "print(\"Predicted Labels:\", predicted_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/us_election_comments_relabelled_final (1).csv\"  # Update with your file's path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Filter relevant comments and extract necessary columns\n",
        "filtered_data = data[data['is_relevant'] == True][['comment', 'label']]\n",
        "comments = filtered_data['comment'].values\n",
        "labels = filtered_data['label'].values\n",
        "\n",
        "# Convert labels to categorical (for classification)\n",
        "labels = labels + 1  # Shift labels from (-1, 0, 1) to (0, 1, 2)\n",
        "labels = to_categorical(labels, num_classes=3)\n",
        "\n",
        "# Parameters\n",
        "VOCAB_SIZE = 30000  # Increased vocabulary size\n",
        "EMBEDDING_DIM = 300  # Larger embeddings for better feature representation\n",
        "MAX_LENGTH = 200  # Allow longer sequences\n",
        "BATCH_SIZE = 64  # Larger batch size for stability\n",
        "EPOCHS = 30  # More epochs for better training\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(comments, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad the sequences\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "# Build the improved LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
        "    Bidirectional(LSTM(256, activation='tanh', return_sequences=True)),  # First LSTM layer\n",
        "    Dropout(0.5),\n",
        "    Bidirectional(LSTM(128, activation='tanh')),  # Second LSTM layer\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # Output layer with softmax for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # Suitable for multi-class classification\n",
        "    metrics=['accuracy']  # Use accuracy as the primary metric\n",
        ")\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Add early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train,\n",
        "    validation_data=(X_test_padded, y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_padded, y_test, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Save the model in the recommended format\n",
        "model.save(\"lstm_sentiment_model.keras\")\n",
        "\n",
        "# Test predictions\n",
        "y_pred_probs = model.predict(X_test_padded)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot encoding to class labels\n",
        "\n",
        "# Calculate additional metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Test with sample comments\n",
        "sample_comments = [\n",
        "    \"I am hopeful about this election!\",\n",
        "    \"This is the worst election in history.\",\n",
        "    \"I don't have a strong opinion about the election.\"\n",
        "]\n",
        "sample_sequences = tokenizer.texts_to_sequences(sample_comments)\n",
        "sample_padded = pad_sequences(sample_sequences, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "predictions = model.predict(sample_padded)\n",
        "print(\"Predictions (probabilities):\", predictions)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1) - 1  # Shift back to original labels (-1, 0, 1)\n",
        "print(\"Predicted Labels:\", predicted_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fPR2y_obrhj-",
        "outputId": "df1f506b-c77b-4917-d80c-26850b90d743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 94ms/step - accuracy: 0.6530 - loss: 0.8356 - val_accuracy: 0.8793 - val_loss: 0.3487\n",
            "Epoch 2/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.8980 - loss: 0.3320 - val_accuracy: 0.9150 - val_loss: 0.2705\n",
            "Epoch 3/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.9139 - loss: 0.2937 - val_accuracy: 0.9415 - val_loss: 0.1591\n",
            "Epoch 4/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.9449 - loss: 0.1381 - val_accuracy: 0.9600 - val_loss: 0.1176\n",
            "Epoch 5/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9874 - loss: 0.0537 - val_accuracy: 0.9772 - val_loss: 0.0915\n",
            "Epoch 6/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.9910 - loss: 0.0412 - val_accuracy: 0.9809 - val_loss: 0.0815\n",
            "Epoch 7/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9970 - loss: 0.0168 - val_accuracy: 0.9809 - val_loss: 0.1009\n",
            "Epoch 8/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9921 - loss: 0.0352 - val_accuracy: 0.9784 - val_loss: 0.0793\n",
            "Epoch 9/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9950 - loss: 0.0205 - val_accuracy: 0.9821 - val_loss: 0.0818\n",
            "Epoch 10/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.9968 - loss: 0.0155 - val_accuracy: 0.9895 - val_loss: 0.0466\n",
            "Epoch 11/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9993 - loss: 0.0058 - val_accuracy: 0.9908 - val_loss: 0.0539\n",
            "Epoch 12/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9932 - val_loss: 0.0450\n",
            "Epoch 13/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9938 - val_loss: 0.0404\n",
            "Epoch 14/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 4.5551e-04 - val_accuracy: 0.9938 - val_loss: 0.0443\n",
            "Epoch 15/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 3.5488e-04 - val_accuracy: 0.9938 - val_loss: 0.0459\n",
            "Epoch 16/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 2.8737e-04 - val_accuracy: 0.9938 - val_loss: 0.0484\n",
            "Epoch 17/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 2.1957e-04 - val_accuracy: 0.9926 - val_loss: 0.0584\n",
            "Epoch 18/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 2.0599e-04 - val_accuracy: 0.9914 - val_loss: 0.0650\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9937 - loss: 0.0400\n",
            "Test Loss: 0.04038211703300476, Test Accuracy: 0.993842363357544\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       1.00      0.95      0.98       129\n",
            "     Neutral       0.99      1.00      1.00      1001\n",
            "    Positive       1.00      1.00      1.00       494\n",
            "\n",
            "    accuracy                           0.99      1624\n",
            "   macro avg       1.00      0.98      0.99      1624\n",
            "weighted avg       0.99      0.99      0.99      1624\n",
            "\n",
            "Confusion Matrix:\n",
            "[[123   6   0]\n",
            " [  0 999   2]\n",
            " [  0   2 492]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Predictions (probabilities): [[2.6474625e-06 9.9999475e-01 2.6372920e-06]\n",
            " [4.0559826e-06 9.9999225e-01 3.7148966e-06]\n",
            " [8.6292912e-06 9.9998653e-01 4.9038276e-06]]\n",
            "Predicted Labels: [0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/us_election_comments_relabelled_final (1).csv\"  # Update with your file's path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Filter relevant comments and extract necessary columns\n",
        "filtered_data = data[data['is_relevant'] == True][['comment', 'label']]\n",
        "comments = filtered_data['comment'].values\n",
        "labels = filtered_data['label'].values\n",
        "\n",
        "# Convert labels to categorical (for classification)\n",
        "labels = labels + 1  # Shift labels from (-1, 0, 1) to (0, 1, 2)\n",
        "labels = to_categorical(labels, num_classes=3)\n",
        "\n",
        "# Parameters\n",
        "VOCAB_SIZE = 30000  # Increased vocabulary size\n",
        "EMBEDDING_DIM = 300  # Larger embeddings for better feature representation\n",
        "MAX_LENGTH = 200  # Allow longer sequences\n",
        "BATCH_SIZE = 64  # Larger batch size for stability\n",
        "EPOCHS = 30  # More epochs for better training\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(comments, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad the sequences\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
        "    Conv1D(128, 5, activation='relu'),  # Convolutional layer with 128 filters and kernel size 5\n",
        "    GlobalMaxPooling1D(),  # Global max pooling to reduce dimensionality\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # Output layer with softmax for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # Suitable for multi-class classification\n",
        "    metrics=['accuracy']  # Use accuracy as the primary metric\n",
        ")\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Add early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train,\n",
        "    validation_data=(X_test_padded, y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_padded, y_test, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Save the model in the recommended format\n",
        "model.save(\"cnn_sentiment_model.keras\")\n",
        "\n",
        "# Test predictions\n",
        "y_pred_probs = model.predict(X_test_padded)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot encoding to class labels\n",
        "\n",
        "# Calculate additional metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Test with sample comments\n",
        "sample_comments = [\n",
        "    \"I am hopeful about this election!\",\n",
        "    \"This is the worst election in history.\",\n",
        "    \"I don't have a strong opinion about the election.\"\n",
        "]\n",
        "sample_sequences = tokenizer.texts_to_sequences(sample_comments)\n",
        "sample_padded = pad_sequences(sample_sequences, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "predictions = model.predict(sample_padded)\n",
        "print(\"Predictions (probabilities):\", predictions)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1) - 1  # Shift back to original labels (-1, 0, 1)\n",
        "print(\"Predicted Labels:\", predicted_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XBEFML9st_5d",
        "outputId": "5a316099-c2f6-41cb-cba4-941b5bb60baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.5875 - loss: 0.9272 - val_accuracy: 0.8467 - val_loss: 0.5178\n",
            "Epoch 2/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8637 - loss: 0.4027 - val_accuracy: 0.9723 - val_loss: 0.1131\n",
            "Epoch 3/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9713 - loss: 0.0929 - val_accuracy: 0.9877 - val_loss: 0.0484\n",
            "Epoch 4/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0306 - val_accuracy: 0.9951 - val_loss: 0.0337\n",
            "Epoch 5/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9972 - loss: 0.0148 - val_accuracy: 0.9951 - val_loss: 0.0467\n",
            "Epoch 6/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0055 - val_accuracy: 0.9951 - val_loss: 0.0493\n",
            "Epoch 7/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0034 - val_accuracy: 0.9951 - val_loss: 0.0513\n",
            "Epoch 8/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0022 - val_accuracy: 0.9951 - val_loss: 0.0541\n",
            "Epoch 9/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.0037 - val_accuracy: 0.9951 - val_loss: 0.0623\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9948 - loss: 0.0304\n",
            "Test Loss: 0.03372427821159363, Test Accuracy: 0.9950739145278931\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.99      0.99      0.99       129\n",
            "     Neutral       1.00      1.00      1.00      1001\n",
            "    Positive       1.00      0.99      0.99       494\n",
            "\n",
            "    accuracy                           1.00      1624\n",
            "   macro avg       0.99      0.99      0.99      1624\n",
            "weighted avg       1.00      1.00      1.00      1624\n",
            "\n",
            "Confusion Matrix:\n",
            "[[128   1   0]\n",
            " [  0 999   2]\n",
            " [  1   4 489]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step\n",
            "Predictions (probabilities): [[4.0608220e-04 9.9954158e-01 5.2347088e-05]\n",
            " [1.2285052e-03 9.9857199e-01 1.9946130e-04]\n",
            " [4.6315207e-04 9.9948013e-01 5.6756391e-05]]\n",
            "Predicted Labels: [0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, LSTM, GlobalMaxPooling1D, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/us_election_comments_relabelled_final (1).csv\"  # Update with your file's path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Filter relevant comments and extract necessary columns\n",
        "filtered_data = data[data['is_relevant'] == True][['comment', 'label']]\n",
        "comments = filtered_data['comment'].values\n",
        "labels = filtered_data['label'].values\n",
        "\n",
        "# Convert labels to categorical (for classification)\n",
        "labels = labels + 1  # Shift labels from (-1, 0, 1) to (0, 1, 2)\n",
        "labels = to_categorical(labels, num_classes=3)\n",
        "\n",
        "# Parameters\n",
        "VOCAB_SIZE = 30000  # Increased vocabulary size\n",
        "EMBEDDING_DIM = 300  # Larger embeddings for better feature representation\n",
        "MAX_LENGTH = 200  # Allow longer sequences\n",
        "BATCH_SIZE = 64  # Larger batch size for stability\n",
        "EPOCHS = 30  # More epochs for better training\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(comments, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad the sequences\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "# Build the corrected Hybrid CNN + LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
        "    Conv1D(128, 5, activation='relu'),  # CNN layer to extract n-gram features\n",
        "    Bidirectional(LSTM(128, activation='tanh', return_sequences=True)),  # LSTM layer for sequential context\n",
        "    GlobalMaxPooling1D(),  # Global max pooling after LSTM\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # Output layer with softmax for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # Suitable for multi-class classification\n",
        "    metrics=['accuracy']  # Use accuracy as the primary metric\n",
        ")\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Add early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train,\n",
        "    validation_data=(X_test_padded, y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_padded, y_test, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Save the model in the recommended format\n",
        "model.save(\"hybrid_cnn_lstm_sentiment_model.keras\")\n",
        "\n",
        "# Test predictions\n",
        "y_pred_probs = model.predict(X_test_padded)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot encoding to class labels\n",
        "\n",
        "# Calculate additional metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Test with sample comments\n",
        "sample_comments = [\n",
        "    \"I am hopeful about this election!\",\n",
        "    \"This is the worst election in history.\",\n",
        "    \"I don't have a strong opinion about the election.\"\n",
        "]\n",
        "sample_sequences = tokenizer.texts_to_sequences(sample_comments)\n",
        "sample_padded = pad_sequences(sample_sequences, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "predictions = model.predict(sample_padded)\n",
        "print(\"Predictions (probabilities):\", predictions)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1) - 1  # Shift back to original labels (-1, 0, 1)\n",
        "print(\"Predicted Labels:\", predicted_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IPh2izwevedy",
        "outputId": "5359dfef-9d40-4f94-a304-52d41a2dac0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_6 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d_2               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d_2               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.6135 - loss: 0.8954 - val_accuracy: 0.8855 - val_loss: 0.3274\n",
            "Epoch 2/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8987 - loss: 0.2770 - val_accuracy: 0.9495 - val_loss: 0.1390\n",
            "Epoch 3/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9834 - loss: 0.0672 - val_accuracy: 0.9846 - val_loss: 0.0660\n",
            "Epoch 4/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9962 - loss: 0.0173 - val_accuracy: 0.9889 - val_loss: 0.0539\n",
            "Epoch 5/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9984 - loss: 0.0071 - val_accuracy: 0.9865 - val_loss: 0.0809\n",
            "Epoch 6/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9997 - loss: 0.0026 - val_accuracy: 0.9920 - val_loss: 0.0653\n",
            "Epoch 7/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.9914 - val_loss: 0.0687\n",
            "Epoch 8/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9995 - loss: 8.9350e-04 - val_accuracy: 0.9914 - val_loss: 0.0758\n",
            "Epoch 9/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.6231e-04 - val_accuracy: 0.9914 - val_loss: 0.0787\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9930 - loss: 0.0397\n",
            "Test Loss: 0.05390453711152077, Test Accuracy: 0.988916277885437\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.95      1.00      0.97       129\n",
            "     Neutral       1.00      0.99      0.99      1001\n",
            "    Positive       0.98      0.99      0.99       494\n",
            "\n",
            "    accuracy                           0.99      1624\n",
            "   macro avg       0.98      0.99      0.98      1624\n",
            "weighted avg       0.99      0.99      0.99      1624\n",
            "\n",
            "Confusion Matrix:\n",
            "[[129   0   0]\n",
            " [  6 987   8]\n",
            " [  1   3 490]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Predictions (probabilities): [[4.9534411e-04 9.9940526e-01 9.9372359e-05]\n",
            " [5.3134125e-05 9.9992490e-01 2.1990838e-05]\n",
            " [2.5920746e-05 9.9996555e-01 8.6009059e-06]]\n",
            "Predicted Labels: [0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/us_election_comments_relabelled_final (1).csv\"  # Update with your file's path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display basic info about the dataset\n",
        "print(\"Basic Info About the Dataset:\")\n",
        "data.info()\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"\\nFirst Few Rows of the Dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Count the number of rows\n",
        "num_rows = len(data)\n",
        "print(f\"\\nNumber of Rows in the Dataset: {num_rows}\")\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"\\nMissing Values in Each Column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Class distribution for sentiment labels\n",
        "if 'label' in data.columns:\n",
        "    class_distribution = data['label'].value_counts()\n",
        "    print(\"\\nClass Distribution for Sentiment Labels:\")\n",
        "    print(class_distribution)\n",
        "else:\n",
        "    print(\"\\nNo 'label' column found in the dataset.\")\n",
        "\n",
        "# Percentage distribution of classes\n",
        "if 'label' in data.columns:\n",
        "    class_percentage = data['label'].value_counts(normalize=True) * 100\n",
        "    print(\"\\nPercentage Distribution for Sentiment Labels:\")\n",
        "    print(class_percentage)\n",
        "\n",
        "# Identify unique subreddits if relevant\n",
        "if 'subreddit' in data.columns:\n",
        "    unique_subreddits = data['subreddit'].nunique()\n",
        "    print(f\"\\nNumber of Unique Subreddits: {unique_subreddits}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a55nFw5CwPj9",
        "outputId": "2f2bddf3-56d9-4b9e-bba0-5e391f797c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basic Info About the Dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8700 entries, 0 to 8699\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   id           8700 non-null   object\n",
            " 1   comment      8700 non-null   object\n",
            " 2   created_utc  8700 non-null   object\n",
            " 3   score        8700 non-null   int64 \n",
            " 4   subreddit    8700 non-null   object\n",
            " 5   is_relevant  8700 non-null   bool  \n",
            " 6   label        8700 non-null   int64 \n",
            "dtypes: bool(1), int64(2), object(4)\n",
            "memory usage: 416.4+ KB\n",
            "\n",
            "First Few Rows of the Dataset:\n",
            "        id                                            comment  \\\n",
            "0  lvfp7bg  to save you a click, ralston says it will be r...   \n",
            "1  lvezm7f  Here's a preview of the story: \\n\\nSeven battl...   \n",
            "2  lvf4uks  Well how absurd is it that the entire country'...   \n",
            "3  lvel24i  \\nAs a reminder, this subreddit [is for civil ...   \n",
            "4  lveohui  >“At least 7 of the keys, maybe 8, clearly fav...   \n",
            "\n",
            "           created_utc  score subreddit  is_relevant  label  \n",
            "0  2024-11-04 22:41:16     14  politics         True      1  \n",
            "1  2024-11-04 21:26:02      2  politics         True      1  \n",
            "2  2024-11-04 21:26:02      5  politics         True      0  \n",
            "3  2024-11-04 20:14:48      1  politics        False      0  \n",
            "4  2024-11-04 20:14:48      1  politics         True      0  \n",
            "\n",
            "Number of Rows in the Dataset: 8700\n",
            "\n",
            "Missing Values in Each Column:\n",
            "id             0\n",
            "comment        0\n",
            "created_utc    0\n",
            "score          0\n",
            "subreddit      0\n",
            "is_relevant    0\n",
            "label          0\n",
            "dtype: int64\n",
            "\n",
            "Class Distribution for Sentiment Labels:\n",
            "label\n",
            " 0    5498\n",
            " 1    2518\n",
            "-1     684\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Percentage Distribution for Sentiment Labels:\n",
            "label\n",
            " 0    63.195402\n",
            " 1    28.942529\n",
            "-1     7.862069\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Number of Unique Subreddits: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Reload the trained model (to ensure it's in a valid state)\n",
        "model_path = \"hybrid_cnn_lstm_sentiment_model.keras\"  # Update with your model's save path\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Ensure class-specific performance\n",
        "print(\"Class-Specific Performance on Test Set:\")\n",
        "y_pred_probs = model.predict(X_test_padded)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot encoding to class labels\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Check for overlap between training and test sets\n",
        "print(\"\\nChecking for Overlap Between Training and Test Sets:\")\n",
        "train_indices = np.arange(len(X_train))  # Indices used for training\n",
        "test_indices = np.arange(len(X_train), len(X_train) + len(X_test))  # Indices used for testing\n",
        "\n",
        "# Extract IDs for training and testing\n",
        "train_ids = set(data.iloc[train_indices]['id'])\n",
        "test_ids = set(data.iloc[test_indices]['id'])\n",
        "\n",
        "overlap = train_ids.intersection(test_ids)\n",
        "if overlap:\n",
        "    print(f\"Overlap Found: {len(overlap)} overlapping entries.\")\n",
        "else:\n",
        "    print(\"No overlap found between training and test sets.\")\n",
        "\n",
        "# Cross-dataset testing (requires a new dataset)\n",
        "new_file_path = \"/content/us_election_comments_relabelled_final (1).csv\"  # Update this with your new dataset's path\n",
        "try:\n",
        "    new_data = pd.read_csv(new_file_path)\n",
        "    new_comments = new_data['comment'].values\n",
        "    new_labels = new_data['label'].values + 1  # Shift labels from (-1, 0, 1) to (0, 1, 2)\n",
        "    new_labels = to_categorical(new_labels, num_classes=3)\n",
        "\n",
        "    # Tokenize and pad the new data\n",
        "    new_sequences = tokenizer.texts_to_sequences(new_comments)\n",
        "    new_padded = pad_sequences(new_sequences, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "    # Evaluate the model on the new dataset\n",
        "    print(\"\\nEvaluating on New Dataset:\")\n",
        "    new_loss, new_accuracy = model.evaluate(new_padded, new_labels, verbose=1)\n",
        "    print(f\"New Dataset Loss: {new_loss}, New Dataset Accuracy: {new_accuracy}\")\n",
        "\n",
        "    # Detailed metrics\n",
        "    new_pred_probs = model.predict(new_padded)\n",
        "    new_pred = np.argmax(new_pred_probs, axis=1)\n",
        "    new_true = np.argmax(new_labels, axis=1)\n",
        "\n",
        "    print(\"Classification Report on New Dataset:\")\n",
        "    print(classification_report(new_true, new_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "except FileNotFoundError:\n",
        "    print(\"New dataset not found. Please provide a valid file path for cross-dataset testing.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WtaE7xpxYl6",
        "outputId": "e98a6556-41bb-4b3c-9855-2848d9befc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class-Specific Performance on Test Set:\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.95      1.00      0.97       129\n",
            "     Neutral       1.00      0.99      0.99      1001\n",
            "    Positive       0.98      0.99      0.99       494\n",
            "\n",
            "    accuracy                           0.99      1624\n",
            "   macro avg       0.98      0.99      0.98      1624\n",
            "weighted avg       0.99      0.99      0.99      1624\n",
            "\n",
            "Confusion Matrix:\n",
            "[[129   0   0]\n",
            " [  6 987   8]\n",
            " [  1   3 490]]\n",
            "\n",
            "Checking for Overlap Between Training and Test Sets:\n",
            "Overlap Found: 1620 overlapping entries.\n",
            "\n",
            "Evaluating on New Dataset:\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9697 - loss: 0.4331\n",
            "New Dataset Loss: 0.39009591937065125, New Dataset Accuracy: 0.9726436734199524\n",
            "\u001b[1m272/272\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
            "Classification Report on New Dataset:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.93      1.00      0.96       684\n",
            "     Neutral       1.00      0.96      0.98      5498\n",
            "    Positive       0.93      1.00      0.96      2518\n",
            "\n",
            "    accuracy                           0.97      8700\n",
            "   macro avg       0.95      0.99      0.97      8700\n",
            "weighted avg       0.97      0.97      0.97      8700\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, LSTM, GlobalMaxPooling1D, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/us_election_comments_relabelled_final (1).csv\"  # Update with your file's path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Filter relevant comments and extract necessary columns\n",
        "filtered_data = data[data['is_relevant'] == True][['id', 'comment', 'label']]\n",
        "\n",
        "# Parameters\n",
        "VOCAB_SIZE = 30000  # Increased vocabulary size\n",
        "EMBEDDING_DIM = 300  # Larger embeddings for better feature representation\n",
        "MAX_LENGTH = 200  # Allow longer sequences\n",
        "BATCH_SIZE = 64  # Larger batch size for stability\n",
        "EPOCHS = 30  # More epochs for better training\n",
        "\n",
        "# Re-split the data to ensure no overlap\n",
        "X = filtered_data['comment']\n",
        "y = filtered_data['label'] + 1  # Shift labels from (-1, 0, 1) to (0, 1, 2)\n",
        "\n",
        "# Ensure no overlap using stratified split\n",
        "data_train, data_test, y_train, y_test = train_test_split(\n",
        "    filtered_data, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Extract training and testing comments\n",
        "X_train = data_train['comment']\n",
        "X_test = data_test['comment']\n",
        "\n",
        "# Convert labels to categorical (for classification)\n",
        "y_train = to_categorical(y_train, num_classes=3)\n",
        "y_test = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad the sequences\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "# Build the Hybrid CNN + LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
        "    Conv1D(128, 5, activation='relu'),  # CNN layer to extract n-gram features\n",
        "    Bidirectional(LSTM(128, activation='tanh', return_sequences=True)),  # LSTM layer for sequential context\n",
        "    GlobalMaxPooling1D(),  # Global max pooling after LSTM\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # Output layer with softmax for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # Suitable for multi-class classification\n",
        "    metrics=['accuracy']  # Use accuracy as the primary metric\n",
        ")\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Add early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train,\n",
        "    validation_data=(X_test_padded, y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_padded, y_test, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Save the model in the recommended format\n",
        "model.save(\"hybrid_cnn_lstm_sentiment_model_no_overlap.keras\")\n",
        "\n",
        "# Test predictions\n",
        "y_pred_probs = model.predict(X_test_padded)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot encoding to class labels\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Optional: Cross-dataset testing\n",
        "new_file_path = \"/content/new_dataset.csv\"  # Update this with your new dataset's path\n",
        "try:\n",
        "    new_data = pd.read_csv(new_file_path)\n",
        "    new_comments = new_data['comment'].values\n",
        "    new_labels = new_data['label'].values + 1  # Shift labels from (-1, 0, 1) to (0, 1, 2)\n",
        "    new_labels = to_categorical(new_labels, num_classes=3)\n",
        "\n",
        "    # Tokenize and pad the new data\n",
        "    new_sequences = tokenizer.texts_to_sequences(new_comments)\n",
        "    new_padded = pad_sequences(new_sequences, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "    # Evaluate the model on the new dataset\n",
        "    print(\"\\nEvaluating on New Dataset:\")\n",
        "    new_loss, new_accuracy = model.evaluate(new_padded, new_labels, verbose=1)\n",
        "    print(f\"New Dataset Loss: {new_loss}, New Dataset Accuracy: {new_accuracy}\")\n",
        "\n",
        "    # Detailed metrics\n",
        "    new_pred_probs = model.predict(new_padded)\n",
        "    new_pred = np.argmax(new_pred_probs, axis=1)\n",
        "    new_true = np.argmax(new_labels, axis=1)\n",
        "\n",
        "    print(\"Classification Report on New Dataset:\")\n",
        "    print(classification_report(new_true, new_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "except FileNotFoundError:\n",
        "    print(\"New dataset not found. Please provide a valid file path for cross-dataset testing.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JKF3odkTy_v-",
        "outputId": "1f6f45f4-363b-45e5-efbd-7b858150b3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_7 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d_3               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d_3               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - accuracy: 0.6308 - loss: 0.8573 - val_accuracy: 0.8812 - val_loss: 0.3235\n",
            "Epoch 2/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9216 - loss: 0.2470 - val_accuracy: 0.9631 - val_loss: 0.1295\n",
            "Epoch 3/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9788 - loss: 0.0679 - val_accuracy: 0.9828 - val_loss: 0.0641\n",
            "Epoch 4/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9979 - loss: 0.0109 - val_accuracy: 0.9883 - val_loss: 0.0794\n",
            "Epoch 5/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9989 - loss: 0.0055 - val_accuracy: 0.9828 - val_loss: 0.0751\n",
            "Epoch 6/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9999 - loss: 0.0019 - val_accuracy: 0.9889 - val_loss: 0.1069\n",
            "Epoch 7/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 0.9877 - val_loss: 0.1003\n",
            "Epoch 8/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.5641e-04 - val_accuracy: 0.9809 - val_loss: 0.1614\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9807 - loss: 0.0605\n",
            "Test Loss: 0.06406502425670624, Test Accuracy: 0.982758641242981\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.93      0.96      0.95       137\n",
            "     Neutral       0.99      0.99      0.99       983\n",
            "    Positive       0.99      0.97      0.98       504\n",
            "\n",
            "    accuracy                           0.98      1624\n",
            "   macro avg       0.97      0.97      0.97      1624\n",
            "weighted avg       0.98      0.98      0.98      1624\n",
            "\n",
            "Confusion Matrix:\n",
            "[[132   2   3]\n",
            " [  6 976   1]\n",
            " [  4  12 488]]\n",
            "New dataset not found. Please provide a valid file path for cross-dataset testing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Define K-Fold Cross Validator\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store results\n",
        "fold_accuracies = []\n",
        "fold_f1_scores = []\n",
        "fold_reports = []\n",
        "\n",
        "# K-Fold Cross-Validation\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(filtered_data)):\n",
        "    print(f\"\\nFold {fold + 1}/{kf.get_n_splits()}\")\n",
        "\n",
        "    # Split data\n",
        "    train_data = filtered_data.iloc[train_index]\n",
        "    val_data = filtered_data.iloc[val_index]\n",
        "\n",
        "    X_train_fold = train_data['comment']\n",
        "    y_train_fold = train_data['label'] + 1  # Shift labels from (-1, 0, 1) to (0, 1, 2)\n",
        "    X_val_fold = val_data['comment']\n",
        "    y_val_fold = val_data['label'] + 1\n",
        "\n",
        "    # Tokenize and pad sequences\n",
        "    X_train_seq = tokenizer.texts_to_sequences(X_train_fold)\n",
        "    X_val_seq = tokenizer.texts_to_sequences(X_val_fold)\n",
        "    X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "    X_val_padded = pad_sequences(X_val_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "    y_train_categorical = to_categorical(y_train_fold, num_classes=3)\n",
        "    y_val_categorical = to_categorical(y_val_fold, num_classes=3)\n",
        "\n",
        "    # Build the model for this fold\n",
        "    model = Sequential([\n",
        "        Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
        "        Conv1D(128, 5, activation='relu'),\n",
        "        Bidirectional(LSTM(128, activation='tanh', return_sequences=True)),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        X_train_padded, y_train_categorical,\n",
        "        epochs=5,  # Use fewer epochs for cross-validation\n",
        "        batch_size=BATCH_SIZE,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    val_loss, val_accuracy = model.evaluate(X_val_padded, y_val_categorical, verbose=0)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Predict on validation data\n",
        "    y_val_pred_probs = model.predict(X_val_padded)\n",
        "    y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
        "    y_val_true = y_val_fold.values\n",
        "\n",
        "    # Calculate F1-score\n",
        "    fold_f1 = f1_score(y_val_true, y_val_pred, average='weighted')\n",
        "    print(f\"F1-Score: {fold_f1:.4f}\")\n",
        "\n",
        "    # Store results\n",
        "    fold_accuracies.append(val_accuracy)\n",
        "    fold_f1_scores.append(fold_f1)\n",
        "    fold_reports.append(classification_report(y_val_true, y_val_pred, target_names=['Negative', 'Neutral', 'Positive'], output_dict=True))\n",
        "\n",
        "# Print overall results\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f}, Std Dev: {np.std(fold_accuracies):.4f}\")\n",
        "print(f\"Mean F1-Score: {np.mean(fold_f1_scores):.4f}, Std Dev: {np.std(fold_f1_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF2Kmp5K0YWq",
        "outputId": "0c9ac52c-2909-49ed-c5dc-4d9427f8b423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0613, Validation Accuracy: 0.9883\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "F1-Score: 0.9883\n",
            "\n",
            "Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0647, Validation Accuracy: 0.9901\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "F1-Score: 0.9902\n",
            "\n",
            "Fold 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0697, Validation Accuracy: 0.9901\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "F1-Score: 0.9901\n",
            "\n",
            "Fold 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0448, Validation Accuracy: 0.9920\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "F1-Score: 0.9920\n",
            "\n",
            "Fold 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0656, Validation Accuracy: 0.9877\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "F1-Score: 0.9877\n",
            "\n",
            "Cross-Validation Results:\n",
            "Mean Accuracy: 0.9897, Std Dev: 0.0015\n",
            "Mean F1-Score: 0.9897, Std Dev: 0.0015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gru\n"
      ],
      "metadata": {
        "id": "MUbXofPi1h4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/us_election_comments_relabelled_final (1).csv\"  # Update with your file's path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Filter relevant comments and extract necessary columns\n",
        "filtered_data = data[data['is_relevant'] == True][['comment', 'label']]\n",
        "comments = filtered_data['comment'].values\n",
        "labels = filtered_data['label'].values\n",
        "\n",
        "# Convert labels to categorical (for classification)\n",
        "labels = labels + 1  # Shift labels from (-1, 0, 1) to (0, 1, 2)\n",
        "labels = to_categorical(labels, num_classes=3)\n",
        "\n",
        "# Parameters\n",
        "VOCAB_SIZE = 30000  # Increased vocabulary size\n",
        "EMBEDDING_DIM = 300  # Larger embeddings for better feature representation\n",
        "MAX_LENGTH = 200  # Allow longer sequences\n",
        "BATCH_SIZE = 64  # Larger batch size for stability\n",
        "EPOCHS = 30  # More epochs for better training\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(comments, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad the sequences\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "# Build the GRU model\n",
        "model = Sequential([\n",
        "    Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
        "    Bidirectional(GRU(128, activation='tanh', return_sequences=True)),\n",
        "    Dropout(0.5),\n",
        "    GRU(64, activation='tanh'),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # Output layer with softmax for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # Suitable for multi-class classification\n",
        "    metrics=['accuracy']  # Use accuracy as the primary metric\n",
        ")\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Add early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train,\n",
        "    validation_data=(X_test_padded, y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_padded, y_test, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Save the model in the recommended format\n",
        "model.save(\"gru_sentiment_model.keras\")\n",
        "\n",
        "# Test predictions\n",
        "y_pred_probs = model.predict(X_test_padded)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot encoding to class labels\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FMw-Z9NF1iwK",
        "outputId": "8a9d369c-f71a-473e-c0f6-3e86f73f775b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_14 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_13 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.5831 - loss: 0.9352 - val_accuracy: 0.6281 - val_loss: 0.8580\n",
            "Epoch 2/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.6220 - loss: 0.8836 - val_accuracy: 0.6595 - val_loss: 0.8134\n",
            "Epoch 3/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.6378 - loss: 0.8629 - val_accuracy: 0.6718 - val_loss: 0.8119\n",
            "Epoch 4/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.6436 - loss: 0.8354 - val_accuracy: 0.6656 - val_loss: 0.8097\n",
            "Epoch 5/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.6358 - loss: 0.8605 - val_accuracy: 0.6718 - val_loss: 0.7854\n",
            "Epoch 6/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.6592 - loss: 0.7897 - val_accuracy: 0.8060 - val_loss: 0.5183\n",
            "Epoch 7/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.8742 - loss: 0.3709 - val_accuracy: 0.9095 - val_loss: 0.1908\n",
            "Epoch 8/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9264 - loss: 0.1491 - val_accuracy: 0.9711 - val_loss: 0.1055\n",
            "Epoch 9/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9701 - loss: 0.0797 - val_accuracy: 0.9760 - val_loss: 0.1161\n",
            "Epoch 10/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.9754 - loss: 0.0693 - val_accuracy: 0.9735 - val_loss: 0.1235\n",
            "Epoch 11/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9859 - loss: 0.0546 - val_accuracy: 0.9711 - val_loss: 0.1260\n",
            "Epoch 12/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9872 - loss: 0.0425 - val_accuracy: 0.9828 - val_loss: 0.0818\n",
            "Epoch 13/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9899 - loss: 0.0344 - val_accuracy: 0.9858 - val_loss: 0.0781\n",
            "Epoch 14/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9951 - loss: 0.0164 - val_accuracy: 0.9920 - val_loss: 0.0755\n",
            "Epoch 15/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9966 - loss: 0.0147 - val_accuracy: 0.9852 - val_loss: 0.0698\n",
            "Epoch 16/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9970 - loss: 0.0120 - val_accuracy: 0.9883 - val_loss: 0.0655\n",
            "Epoch 17/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 0.9895 - val_loss: 0.0825\n",
            "Epoch 18/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9992 - loss: 0.0045 - val_accuracy: 0.9877 - val_loss: 0.0859\n",
            "Epoch 19/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.2353e-04 - val_accuracy: 0.9877 - val_loss: 0.0915\n",
            "Epoch 20/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.2463e-04 - val_accuracy: 0.9877 - val_loss: 0.0926\n",
            "Epoch 21/30\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.6757e-04 - val_accuracy: 0.9889 - val_loss: 0.0934\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9883 - loss: 0.0654\n",
            "Test Loss: 0.06548026949167252, Test Accuracy: 0.9883005023002625\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.98      0.95      0.97       129\n",
            "     Neutral       0.99      0.99      0.99      1001\n",
            "    Positive       0.99      0.99      0.99       494\n",
            "\n",
            "    accuracy                           0.99      1624\n",
            "   macro avg       0.99      0.98      0.98      1624\n",
            "weighted avg       0.99      0.99      0.99      1624\n",
            "\n",
            "Confusion Matrix:\n",
            "[[123   4   2]\n",
            " [  2 995   4]\n",
            " [  0   7 487]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross validation"
      ],
      "metadata": {
        "id": "Xo8a1lBO21VJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Parameters\n",
        "VOCAB_SIZE = 30000\n",
        "EMBEDDING_DIM = 300\n",
        "MAX_LENGTH = 200\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5  # Use fewer epochs for cross-validation\n",
        "\n",
        "# Define K-Fold Cross Validator\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store results\n",
        "fold_accuracies = []\n",
        "fold_f1_scores = []\n",
        "fold_reports = []\n",
        "\n",
        "# K-Fold Cross-Validation\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(comments)):\n",
        "    print(f\"\\nFold {fold + 1}/{kf.get_n_splits()}\")\n",
        "\n",
        "    # Split data\n",
        "    X_train_fold = comments[train_index]\n",
        "    y_train_fold = labels[train_index]\n",
        "    X_val_fold = comments[val_index]\n",
        "    y_val_fold = labels[val_index]\n",
        "\n",
        "    # Tokenize and pad sequences\n",
        "    tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(X_train_fold)\n",
        "\n",
        "    X_train_seq = tokenizer.texts_to_sequences(X_train_fold)\n",
        "    X_val_seq = tokenizer.texts_to_sequences(X_val_fold)\n",
        "    X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "    X_val_padded = pad_sequences(X_val_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "    # Build the GRU model\n",
        "    model = Sequential([\n",
        "        Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
        "        Bidirectional(GRU(128, activation='tanh', return_sequences=True)),\n",
        "        Dropout(0.5),\n",
        "        GRU(64, activation='tanh'),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        X_train_padded, y_train_fold,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    val_loss, val_accuracy = model.evaluate(X_val_padded, y_val_fold, verbose=0)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Predict on validation data\n",
        "    y_val_pred_probs = model.predict(X_val_padded)\n",
        "    y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
        "    y_val_true = np.argmax(y_val_fold, axis=1)\n",
        "\n",
        "    # Calculate F1-score\n",
        "    fold_f1 = f1_score(y_val_true, y_val_pred, average='weighted')\n",
        "    print(f\"F1-Score: {fold_f1:.4f}\")\n",
        "\n",
        "    # Store results\n",
        "    fold_accuracies.append(val_accuracy)\n",
        "    fold_f1_scores.append(fold_f1)\n",
        "    fold_reports.append(classification_report(y_val_true, y_val_pred, target_names=['Negative', 'Neutral', 'Positive'], output_dict=True))\n",
        "\n",
        "# Print overall results\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f}, Std Dev: {np.std(fold_accuracies):.4f}\")\n",
        "print(f\"Mean F1-Score: {np.mean(fold_f1_scores):.4f}, Std Dev: {np.std(fold_f1_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trC9TU3U22wV",
        "outputId": "9ee00a60-bdd8-42b3-ec20-635a40c51abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7967, Validation Accuracy: 0.6749\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "F1-Score: 0.5902\n",
            "\n",
            "Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8387, Validation Accuracy: 0.6359\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "F1-Score: 0.5258\n",
            "\n",
            "Fold 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8346, Validation Accuracy: 0.6525\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "F1-Score: 0.5512\n",
            "\n",
            "Fold 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8001, Validation Accuracy: 0.6531\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "F1-Score: 0.5559\n",
            "\n",
            "Fold 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8182, Validation Accuracy: 0.6476\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "F1-Score: 0.5567\n",
            "\n",
            "Cross-Validation Results:\n",
            "Mean Accuracy: 0.6528, Std Dev: 0.0127\n",
            "Mean F1-Score: 0.5560, Std Dev: 0.0205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use"
      ],
      "metadata": {
        "id": "tU0HRsUv3sew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PO-9rc2A3tQN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "stratifiedkfold"
      ],
      "metadata": {
        "id": "atCahz-_3tTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Define Stratified K-Fold\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Compute class weights\n",
        "y_classes = np.argmax(labels, axis=1)  # Convert one-hot to class labels\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_classes), y=y_classes)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Initialize tokenizer once\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(comments)\n",
        "\n",
        "fold_accuracies, fold_f1_scores = [], []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(comments, y_classes)):\n",
        "    print(f\"Fold {fold + 1}/5\")\n",
        "\n",
        "    # Split data\n",
        "    X_train_fold, X_val_fold = comments[train_index], comments[val_index]\n",
        "    y_train_fold, y_val_fold = labels[train_index], labels[val_index]\n",
        "\n",
        "    # Tokenize and pad\n",
        "    X_train_seq = tokenizer.texts_to_sequences(X_train_fold)\n",
        "    X_val_seq = tokenizer.texts_to_sequences(X_val_fold)\n",
        "    X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "    X_val_padded = pad_sequences(X_val_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "    # Build GRU model\n",
        "    model = Sequential([\n",
        "        Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
        "        Bidirectional(GRU(128, activation='tanh', return_sequences=True)),\n",
        "        Dropout(0.5),\n",
        "        GRU(64, activation='tanh'),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train model\n",
        "    model.fit(\n",
        "        X_train_padded, y_train_fold,\n",
        "        epochs=10,  # Slightly increase epochs\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_weight=class_weights,  # Apply class weights\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    val_loss, val_accuracy = model.evaluate(X_val_padded, y_val_fold, verbose=1)\n",
        "    y_val_pred_probs = model.predict(X_val_padded)\n",
        "    y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
        "    y_val_true = np.argmax(y_val_fold, axis=1)\n",
        "\n",
        "    # Metrics\n",
        "    f1 = f1_score(y_val_true, y_val_pred, average='weighted')\n",
        "    fold_accuracies.append(val_accuracy)\n",
        "    fold_f1_scores.append(f1)\n",
        "    print(f\"Fold {fold + 1}: Accuracy={val_accuracy:.4f}, F1-Score={f1:.4f}\")\n",
        "\n",
        "# Summary\n",
        "print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f}, Std Dev: {np.std(fold_accuracies):.4f}\")\n",
        "print(f\"Mean F1-Score: {np.mean(fold_f1_scores):.4f}, Std Dev: {np.std(fold_f1_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82DI8mZx3vBy",
        "outputId": "500aeb5b-531a-4e94-d800-800114a4651a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.4220 - loss: 1.0986\n",
            "Epoch 2/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4185 - loss: 1.0857\n",
            "Epoch 3/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.4244 - loss: 1.0508\n",
            "Epoch 4/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.5128 - loss: 1.0021\n",
            "Epoch 5/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4551 - loss: 1.0232\n",
            "Epoch 6/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5340 - loss: 1.0053\n",
            "Epoch 7/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.4553 - loss: 1.0348\n",
            "Epoch 8/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.5326 - loss: 0.9900\n",
            "Epoch 9/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5773 - loss: 0.9969\n",
            "Epoch 10/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.6137 - loss: 0.9937\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6524 - loss: 1.0512\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
            "Fold 1: Accuracy=0.6564, F1-Score=0.5648\n",
            "Fold 2/5\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.3907 - loss: 1.1203\n",
            "Epoch 2/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.4518 - loss: 1.0931\n",
            "Epoch 3/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4567 - loss: 1.0706\n",
            "Epoch 4/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.4378 - loss: 1.0395\n",
            "Epoch 5/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.5082 - loss: 1.0360\n",
            "Epoch 6/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4970 - loss: 1.0145\n",
            "Epoch 7/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.5307 - loss: 1.0188\n",
            "Epoch 8/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.5424 - loss: 1.0161\n",
            "Epoch 9/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.5998 - loss: 0.9935\n",
            "Epoch 10/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6103 - loss: 1.0128\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6668 - loss: 0.9692\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "Fold 2: Accuracy=0.6482, F1-Score=0.5493\n",
            "Fold 3/5\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.4035 - loss: 1.1039\n",
            "Epoch 2/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.4209 - loss: 1.0976\n",
            "Epoch 3/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.4703 - loss: 1.0544\n",
            "Epoch 4/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.4827 - loss: 1.0175\n",
            "Epoch 5/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.5542 - loss: 1.0029\n",
            "Epoch 6/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.5728 - loss: 1.0049\n",
            "Epoch 7/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.6097 - loss: 1.0016\n",
            "Epoch 8/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6112 - loss: 1.0354\n",
            "Epoch 9/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4663 - loss: 1.0339\n",
            "Epoch 10/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.5997 - loss: 0.9722\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6479 - loss: 0.9095\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "Fold 3: Accuracy=0.6488, F1-Score=0.5857\n",
            "Fold 4/5\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.3569 - loss: 1.1075\n",
            "Epoch 2/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.4579 - loss: 1.0669\n",
            "Epoch 3/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.3690 - loss: 1.1540\n",
            "Epoch 4/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.4098 - loss: 1.0328\n",
            "Epoch 5/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4561 - loss: 1.0180\n",
            "Epoch 6/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.4550 - loss: 1.0267\n",
            "Epoch 7/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.5190 - loss: 1.0158\n",
            "Epoch 8/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.6011 - loss: 1.0225\n",
            "Epoch 9/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.5770 - loss: 1.0115\n",
            "Epoch 10/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.6345 - loss: 0.9904\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6412 - loss: 1.0430\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "Fold 4: Accuracy=0.6482, F1-Score=0.5477\n",
            "Fold 5/5\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - accuracy: 0.4291 - loss: 1.1104\n",
            "Epoch 2/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4851 - loss: 1.0608\n",
            "Epoch 3/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4063 - loss: 1.0558\n",
            "Epoch 4/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5329 - loss: 0.9976\n",
            "Epoch 5/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.4076 - loss: 1.0186\n",
            "Epoch 6/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4942 - loss: 1.0301\n",
            "Epoch 7/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.4511 - loss: 1.0069\n",
            "Epoch 8/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.4443 - loss: 0.9851\n",
            "Epoch 9/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.5269 - loss: 0.9913\n",
            "Epoch 10/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.5549 - loss: 1.0262\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6682 - loss: 1.0358\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "Fold 5: Accuracy=0.6550, F1-Score=0.5598\n",
            "Mean Accuracy: 0.6513, Std Dev: 0.0036\n",
            "Mean F1-Score: 0.5614, Std Dev: 0.0137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "change parameters"
      ],
      "metadata": {
        "id": "X0NaJ8-b5jZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Parameters\n",
        "VOCAB_SIZE = 30000\n",
        "EMBEDDING_DIM = 300\n",
        "MAX_LENGTH = 200\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 15  # Increased epochs for better convergence\n",
        "LEARNING_RATE = 0.0001  # Lower learning rate for stability\n",
        "\n",
        "# Define Stratified K-Fold\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Compute class weights\n",
        "y_classes = np.argmax(labels, axis=1)  # Convert one-hot to class labels\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_classes), y=y_classes)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Initialize tokenizer once\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(comments)\n",
        "\n",
        "fold_accuracies, fold_f1_scores = [], []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(comments, y_classes)):\n",
        "    print(f\"Fold {fold + 1}/5\")\n",
        "\n",
        "    # Split data\n",
        "    X_train_fold, X_val_fold = comments[train_index], comments[val_index]\n",
        "    y_train_fold, y_val_fold = labels[train_index], labels[val_index]\n",
        "\n",
        "    # Tokenize and pad\n",
        "    X_train_seq = tokenizer.texts_to_sequences(X_train_fold)\n",
        "    X_val_seq = tokenizer.texts_to_sequences(X_val_fold)\n",
        "    X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "    X_val_padded = pad_sequences(X_val_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "    # Build the revised GRU model\n",
        "    model = Sequential([\n",
        "        Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
        "        Bidirectional(GRU(64, activation='tanh', return_sequences=True)),  # Reduced units for stability\n",
        "        Dropout(0.6),  # Increased dropout\n",
        "        GRU(32, activation='tanh'),\n",
        "        Dropout(0.6),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.6),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        X_train_padded, y_train_fold,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_weight=class_weights,  # Apply class weights\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    val_loss, val_accuracy = model.evaluate(X_val_padded, y_val_fold, verbose=1)\n",
        "    y_val_pred_probs = model.predict(X_val_padded)\n",
        "    y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
        "    y_val_true = np.argmax(y_val_fold, axis=1)\n",
        "\n",
        "    # Metrics\n",
        "    f1 = f1_score(y_val_true, y_val_pred, average='weighted')\n",
        "    fold_accuracies.append(val_accuracy)\n",
        "    fold_f1_scores.append(f1)\n",
        "    print(f\"Fold {fold + 1}: Accuracy={val_accuracy:.4f}, F1-Score={f1:.4f}\")\n",
        "\n",
        "# Summary\n",
        "print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f}, Std Dev: {np.std(fold_accuracies):.4f}\")\n",
        "print(f\"Mean F1-Score: {np.mean(fold_f1_scores):.4f}, Std Dev: {np.std(fold_f1_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFB9PGRv5klz",
        "outputId": "e2bb5249-bb98-49e9-978d-8d3c8f350e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.4294 - loss: 1.0975\n",
            "Epoch 2/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - accuracy: 0.3583 - loss: 1.1103\n",
            "Epoch 3/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.4084 - loss: 1.0819\n",
            "Epoch 4/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.3408 - loss: 1.0812\n",
            "Epoch 5/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.4542 - loss: 1.0378\n",
            "Epoch 6/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.4356 - loss: 1.0501\n",
            "Epoch 7/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.4512 - loss: 1.0062\n",
            "Epoch 8/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.4830 - loss: 1.0178\n",
            "Epoch 9/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.5803 - loss: 0.9913\n",
            "Epoch 10/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.5791 - loss: 0.9930\n",
            "Epoch 11/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.5325 - loss: 1.0128\n",
            "Epoch 12/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5737 - loss: 1.0207\n",
            "Epoch 13/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5781 - loss: 0.9872\n",
            "Epoch 14/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.5932 - loss: 0.9941\n",
            "Epoch 15/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.6243 - loss: 0.9858\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6619 - loss: 1.0104\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "Fold 1: Accuracy=0.6687, F1-Score=0.5873\n",
            "Fold 2/5\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.2946 - loss: 1.1103\n",
            "Epoch 2/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.3797 - loss: 1.0912\n",
            "Epoch 3/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.3159 - loss: 1.0910\n",
            "Epoch 4/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4520 - loss: 1.0630\n",
            "Epoch 5/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.4005 - loss: 1.0710\n",
            "Epoch 6/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.4769 - loss: 1.0464\n",
            "Epoch 7/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5329 - loss: 1.0228\n",
            "Epoch 8/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5412 - loss: 1.0191\n",
            "Epoch 9/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5672 - loss: 1.0309\n",
            "Epoch 10/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.6173 - loss: 1.0126\n",
            "Epoch 11/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5964 - loss: 1.0158\n",
            "Epoch 12/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.5849 - loss: 0.9975\n",
            "Epoch 13/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.5676 - loss: 0.9924\n",
            "Epoch 14/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.6110 - loss: 0.9417\n",
            "Epoch 15/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.7863 - loss: 0.6101\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8952 - loss: 0.5453\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "Fold 2: Accuracy=0.8965, F1-Score=0.8722\n",
            "Fold 3/5\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - accuracy: 0.3680 - loss: 1.1088\n",
            "Epoch 2/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.4012 - loss: 1.0993\n",
            "Epoch 3/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.4436 - loss: 1.0587\n",
            "Epoch 4/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.3947 - loss: 1.0874\n",
            "Epoch 5/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.4330 - loss: 1.0314\n",
            "Epoch 6/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.4034 - loss: 1.0397\n",
            "Epoch 7/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.4750 - loss: 1.0008\n",
            "Epoch 8/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.4438 - loss: 1.0260\n",
            "Epoch 9/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.5030 - loss: 1.0155\n",
            "Epoch 10/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.5666 - loss: 1.0022\n",
            "Epoch 11/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5505 - loss: 1.0124\n",
            "Epoch 12/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.6078 - loss: 1.0154\n",
            "Epoch 13/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.6174 - loss: 0.9904\n",
            "Epoch 14/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.6012 - loss: 1.0059\n",
            "Epoch 15/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.6412 - loss: 0.9903\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6403 - loss: 1.0356\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Fold 3: Accuracy=0.6543, F1-Score=0.5611\n",
            "Fold 4/5\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.3303 - loss: 1.1276\n",
            "Epoch 2/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - accuracy: 0.3461 - loss: 1.1047\n",
            "Epoch 3/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.3790 - loss: 1.0769\n",
            "Epoch 4/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.3373 - loss: 1.0745\n",
            "Epoch 5/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - accuracy: 0.3938 - loss: 1.0680\n",
            "Epoch 6/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.3586 - loss: 1.0445\n",
            "Epoch 7/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.4191 - loss: 1.0288\n",
            "Epoch 8/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.4831 - loss: 1.0579\n",
            "Epoch 9/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.5272 - loss: 1.0268\n",
            "Epoch 10/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.5275 - loss: 1.0218\n",
            "Epoch 11/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6173 - loss: 0.9851\n",
            "Epoch 12/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5118 - loss: 1.0478\n",
            "Epoch 13/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.6010 - loss: 1.0285\n",
            "Epoch 14/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.6176 - loss: 0.9914\n",
            "Epoch 15/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.6346 - loss: 0.9900\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6440 - loss: 1.0286\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "Fold 4: Accuracy=0.6513, F1-Score=0.5544\n",
            "Fold 5/5\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.4158 - loss: 1.0780\n",
            "Epoch 2/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.3596 - loss: 1.1065\n",
            "Epoch 3/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.3558 - loss: 1.0922\n",
            "Epoch 4/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.4442 - loss: 1.0541\n",
            "Epoch 5/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.4080 - loss: 1.0437\n",
            "Epoch 6/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.4559 - loss: 1.0287\n",
            "Epoch 7/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.4836 - loss: 0.9953\n",
            "Epoch 8/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5444 - loss: 1.0233\n",
            "Epoch 9/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.5367 - loss: 1.0283\n",
            "Epoch 10/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.5770 - loss: 1.0083\n",
            "Epoch 11/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5901 - loss: 1.0049\n",
            "Epoch 12/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.6138 - loss: 1.0181\n",
            "Epoch 13/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6188 - loss: 0.9905\n",
            "Epoch 14/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.5881 - loss: 0.9961\n",
            "Epoch 15/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.6677 - loss: 0.9121\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8769 - loss: 0.6323\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "Fold 5: Accuracy=0.8737, F1-Score=0.8741\n",
            "Mean Accuracy: 0.7489, Std Dev: 0.1116\n",
            "Mean F1-Score: 0.6898, Std Dev: 0.1501\n"
          ]
        }
      ]
    }
  ]
}